{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c505fc-f355-4f76-8018-01377b43f277",
   "metadata": {},
   "source": [
    "# Hybrid search with Qdrant\n",
    "Vector search based on dense embeddings captures the semantics in data so is not necessary to look for the same terms in queries and documents and still be able to find relevant items<br><br>\n",
    "There are other methods that rely on the presence of keywords:\n",
    "- Bag-of-Words\n",
    "- TF-IDF\n",
    "- BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c84aa9f-a463-4c9d-886f-5b9cf000db08",
   "metadata": {},
   "source": [
    "## Sparse Vectors\n",
    "Means the majority of the dimensions of such vector are just zeros, a non-zero value at a particular dimension indicates the presence of a term from the dictionary assigned to that position.\n",
    "\n",
    "Since vectors are sparce, the dictionary can theoretically grow indefinitely, as we can append a new term at the very end.\n",
    "\n",
    "## BM25\n",
    "BM25 is an industry standard. It's a statistical model (no neural networks involved), which makes it really fast and lightweight. It's usually a solid baseline in search benchmarks so you should not ignore it.\n",
    "\n",
    "BM25 is a ranking function that helps search engines determine how relevant a document is to a query by combining two key concepts: Term Frequency (TF) and Inverse Document Frequency (IDF).\n",
    "\n",
    "1. The Term Frequency component rewards documents that contain the query terms multiple times, but with diminishing returns - so a document with 10 occurrences of a word isn't necessarily 10 times better than one with just 1 occurrence.\n",
    "2. The Inverse Document Frequency part boosts the importance of rare words while reducing the weight of common words that appear in many documents, since rare terms are typically more informative for distinguishing relevant results.\n",
    "\n",
    "BM25 also incorporates document length normalization to prevent longer documents from having an unfair advantage simply due to their size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b646e7-4eae-41ee-a82d-1ced44d2ed40",
   "metadata": {},
   "source": [
    "# Step 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13dc448c-fe9a-4a19-b3b0-124ed3b1f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install -q \"qdrant-client[fastembed]>=1.14.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d9131-a0d7-4c30-860e-6e4d2a81ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker run -d -p 6333:6333 -p 6334:6334 \\\n",
    "#    -v \"./qdrant_storage:/qdrant/storage:z\" \\\n",
    "#    qdrant/qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8f85c7-2f0f-420b-9773-dadb34dba815",
   "metadata": {},
   "source": [
    "# Step 1: Connect to Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce3ed906-0f24-4e30-aefd-cc50f8b8d5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='zoomcamp-rag'), CollectionDescription(name='zoomcamp-faq')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient('http://localhost:6333')\n",
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78ef629-89ed-4d22-bc29-d4cfa5be0d6f",
   "metadata": {},
   "source": [
    "# Step 2: Sparse vector search with BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae858ad0-6741-4991-ad45-067e02d38142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1baf3c29-1a99-4609-b40e-32755d1d4b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_raw[0]['documents'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df776bd-d743-4060-a13b-94a610d08c6d",
   "metadata": {},
   "source": [
    "We need to create a collection first. Qdrant will handle the IDF calculations, if we configure it to. That's required for BM25, otherwise it won't boost the rare words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8f4c9e5-acba-48d5-a164-33339cbcbc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import models\n",
    "\n",
    "# Create the collection with specified sparse vector parameters\n",
    "client.create_collection(\n",
    "    collection_name='zoomcamp-sparse',\n",
    "    sparse_vectors_config={\n",
    "        'bm25': models.SparseVectorParams(\n",
    "            modifier=models.Modifier.IDF,\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a729b96-4d58-4772-983b-2e21f182d483",
   "metadata": {},
   "source": [
    "FastEmbed comes with a BM25 implementation that we can use as any other model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80647828-7b4d-46a0-9834-91878ab04e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ba715614494a0e8ef35d38a16fa0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa2c2daa8fa4399b05ac9987caf94ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "german.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6b2533ed374faeb55f4b847be51347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "english.txt:   0%|          | 0.00/936 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2088f464de464697f53cec291c8392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "finnish.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6255f3848a1c49fead700751267940ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4617f0acb411403a96831d18f2c964e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french.txt:   0%|          | 0.00/813 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c8600389ce4792a1064178a6485f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dutch.txt:   0%|          | 0.00/453 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3685d5f0f7e1469c8c3771afde69c897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "danish.txt:   0%|          | 0.00/424 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3593968af88c4f4a8577a87ea8359875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "arabic.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e39daccc1d641898d6abcba5faa01ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "greek.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571788ec4f2b47b0900267b0ae962334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "portuguese.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f76da7ca9d4117b605bd3368e4f21c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hungarian.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778dc61993e841d5b7a635d2a1f126df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "italian.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63da3fb71474553afc16070144e7a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "norwegian.txt:   0%|          | 0.00/851 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9086956231f24074a4b8a8e89cff4d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "russian.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "632112c06ec14c678bfb041e4fe4f38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "romanian.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6807b53850dd44e6a9bdcb5df7ff1bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spanish.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4f6e7f8e4d41afb5be886d44b64359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "swedish.txt:   0%|          | 0.00/559 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ba2a01bc054fb1bd608b7b9dcf4162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "turkish.txt:   0%|          | 0.00/260 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "# Send the points to the collection\n",
    "client.upsert(\n",
    "    collection_name='zoomcamp-sparse',\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=uuid.uuid4().hex,\n",
    "            vector={\n",
    "                'bm25': models.Document(\n",
    "                    text=doc['text'],\n",
    "                    model='Qdrant/bm25',\n",
    "                ),\n",
    "            },\n",
    "            payload={\n",
    "                'text': doc['text'],\n",
    "                'section': doc['section'],\n",
    "                'course': course['course'],\n",
    "            }\n",
    "        )\n",
    "        for course in documents_raw\n",
    "        for doc in course['documents']\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168eec93-6799-4a61-9b67-cc656af2737a",
   "metadata": {},
   "source": [
    "BM25 does not require a neural network, so it is fast compared to dense embedding models.\n",
    "# Step 3: Running sparse vector search with BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60e0c8ce-6614-47f2-a0b3-5c7f07a9af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query: str, limit: int = 1) -> list[models.ScoredPoint]:\n",
    "    results = client.query_points(\n",
    "        collection_name=\"zoomcamp-sparse\",\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=\"Qdrant/bm25\",\n",
    "        ),\n",
    "        using=\"bm25\",\n",
    "        limit=limit,\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "    return results.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "583682c1-f98d-4cf9-aba5-2d988ffc8200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = search('Qdrant')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af31549e-342d-44b3-b643-74a592b2d999",
   "metadata": {},
   "source": [
    "Sparse vectors can return no results, if none of the keywords from the query were ever used in the documents. No matter if there are some synonyms. Terminology does matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37f2cd99-f25a-4e75-a462-c31c611ec2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can use round() function or f-strings\n",
      "round(number, 4)  - this will round number up to 4 decimal places\n",
      "print(f'Average mark for the Homework is {avg:.3f}') - using F string\n",
      "Also there is pandas.Series. round idf you need to round values in the whole Series\n",
      "Please check the documentation\n",
      "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.round.html#pandas.Series.round\n",
      "Added by Olga Rudakova\n"
     ]
    }
   ],
   "source": [
    "results = search(\"pandas\")\n",
    "print(results[0].payload[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df8bf25-2aed-49f7-8c33-15121c95347b",
   "metadata": {},
   "source": [
    "Scores returned by BM25 are not calculated with cosine similarity, but with BM25 formula. They are not bounded to a specific range, but are virtually unbounded. Let's see how they may look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d097f562-6e3a-4f5c-bd45-c76c62474e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0392046"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869d254c-d58a-4308-8f47-635ec6c568ff",
   "metadata": {},
   "source": [
    "## Natural language like queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a34cc4e-4215-40f4-94a1-c8851d5626f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"text\": \"Even though the upload works using aws cli and boto3 in Jupyter notebook.\\nSolution set the AWS_PROFILE environment variable (the default profile is called default)\",\n",
      "    \"section\": \"Module 4: Deployment\",\n",
      "    \"question\": \"Uploading to s3 fails with An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The AWS Access Key Id you provided does not exist in our records.\\\"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "random.seed(202506)\n",
    "\n",
    "course = random.choice(documents_raw)\n",
    "course_piece = random.choice(course[\"documents\"])\n",
    "print(json.dumps(course_piece, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c7d3361-7a9e-4d0f-9b2b-ee3242b542f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trial dbt account provides access to dbt API. Job will still be needed to be added manually. Airflow will run the job using a python operator calling the API. You will need to provide api key, job id, etc. (be careful not committing it to Github).\n",
      "Detailed explanation here: https://docs.getdbt.com/blog/dbt-airflow-spiritual-alignment\n",
      "Source code example here: https://github.com/sungchun12/airflow-toolkit/blob/95d40ac76122de337e1b1cdc8eed35ba1c3051ed/dags/examples/dbt_cloud_example.py\n"
     ]
    }
   ],
   "source": [
    "results = search(course_piece[\"question\"])\n",
    "print(results[0].payload[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2b9d26-5a32-434a-a491-83480c4960a0",
   "metadata": {},
   "source": [
    "# Step 4: Qdrant Uiversal Query API - prefetching\n",
    "Qdrant's .query_points method allows building multi-step search pipelines which can incorporate various methods into a single call. For example, we can retrieve some candidates with dense vector search, and then rerank them with sparse search, or use a fast method for initial retrieval and precise, but slow, reranking.\n",
    "\n",
    "Let's create another collection that will keep both dense and sparse representations. Qdrant named vectors allow us to store multiple representations per point and it proves useful especially when we want to use mulitple models in our applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25fde77d-4a89-447a-bc97-ef8a1374a1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the collection with both vector types\n",
    "client.create_collection(\n",
    "    collection_name='zoomcamp-sparse-and-dense',\n",
    "    vectors_config={\n",
    "        # Named dense vector for jinaai/jina-embeddings-v2-small-en\n",
    "        \"jina-small\": models.VectorParams(\n",
    "            size=512,\n",
    "            distance=models.Distance.COSINE,\n",
    "        ),\n",
    "    },\n",
    "    sparse_vectors_config={\n",
    "        'bm25': models.SparseVectorParams(\n",
    "            modifier=models.Modifier.IDF,\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365c9490-36f8-43ff-b7ad-d01d0b9a251a",
   "metadata": {},
   "source": [
    "Upload all the vectors into the newly created collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "598713b7-b3c7-45a9-84d4-9d980819f248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca46803a0fa4b429e68ea343d346913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a23e527a4c4964ae174b890d07ff6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f52aff21bf41fd8f7559e513e00983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/model.onnx:   0%|          | 0.00/130M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead8843982fd401c8a12afa292b3e1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/367 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde7dd710cc9489a867de1e0d445d99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df83268bc4d4a14bfb7cb2d22b60089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.upsert(\n",
    "    collection_name=\"zoomcamp-sparse-and-dense\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=uuid.uuid4().hex,\n",
    "            vector={\n",
    "                \"jina-small\": models.Document(\n",
    "                    text=doc[\"text\"],\n",
    "                    model=\"jinaai/jina-embeddings-v2-small-en\",\n",
    "                ),\n",
    "                \"bm25\": models.Document(\n",
    "                    text=doc[\"text\"], \n",
    "                    model=\"Qdrant/bm25\",\n",
    "                ),\n",
    "            },\n",
    "            payload={\n",
    "                \"text\": doc[\"text\"],\n",
    "                \"section\": doc[\"section\"],\n",
    "                \"course\": course[\"course\"],\n",
    "            }\n",
    "        )\n",
    "        for course in documents_raw\n",
    "        for doc in course[\"documents\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8339deaf-5242-4235-9852-58564cd25e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_stage_search(query: str, limit: int = 1) -> list[models.ScoredPoint]:\n",
    "    results = client.query_points(\n",
    "        collection_name=\"zoomcamp-sparse-and-dense\",\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"jinaai/jina-embeddings-v2-small-en\",\n",
    "                ),\n",
    "                using=\"jina-small\",\n",
    "                # Prefetch ten times more results, then\n",
    "                # expected to return, so we can really rerank\n",
    "                limit=(10 * limit),\n",
    "            ),\n",
    "        ],\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=\"Qdrant/bm25\", \n",
    "        ),\n",
    "        using=\"bm25\",\n",
    "        limit=limit,\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "    return results.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1af2ab0e-5bac-4785-a2d5-f9feda31fbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"text\": \"Even though the upload works using aws cli and boto3 in Jupyter notebook.\\nSolution set the AWS_PROFILE environment variable (the default profile is called default)\",\n",
      "    \"section\": \"Module 4: Deployment\",\n",
      "    \"question\": \"Uploading to s3 fails with An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The AWS Access Key Id you provided does not exist in our records.\\\"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(course_piece, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c98b0119-8a01-4abe-94ff-c0cb38817d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem description. How can we connect s3 bucket to MLFLOW?\n",
      "Solution: Use boto3 and AWS CLI to store access keys. The access keys are what will be used by boto3 (AWS' Python API tool) to connect with the AWS servers. If there are no Access Keys how can they make sure that they have the right to access this Bucket? Maybe you're a malicious actor (Hacker for ex). The keys must be present for boto3 to talk to the AWS servers and they will provide access to the Bucket if you possess the right permissions. You can always set the Bucket as public so anyone can access it, now you don't need access keys because AWS won't care.\n",
      "Read more here: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html\n",
      "Added by Akshit Miglani\n"
     ]
    }
   ],
   "source": [
    "results = multi_stage_search(course_piece[\"question\"])\n",
    "print(results[0].payload[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725f81df-1504-44d8-b629-7cb52ff30a1d",
   "metadata": {},
   "source": [
    "# Step 5: Building Hybrid Search\n",
    "In real production systems, you don't need to choose just one vector type. You never know what kind of queries your users will send to the system. E-commerce search might be just fine with lexical search on top of sparse vectors, as people will tend to send keywords, but in conversational systems, such as chatbots, natural language questions might be more frequent. Using one model as a retriever and another one as reranker is not the only way of how to use dense and sparse in a single system.\n",
    "\n",
    "Hybrid Search is a technique for combining results coming from different search methods - for example dense and sparse. There isn't a clear definition of how exactly to implement it, as the main problem is how to mix results coming from methods which are incompatible. Dense and sparse search scores can't be compared directly, so we need another method that will order the final results somehow.\n",
    "\n",
    "There are two terms important for Hybrid Search: **fusion** and **reranking**.\n",
    "\n",
    "## Fusion\n",
    "Fusion is a set of methods which work on the scores/ranking as returned by the individual methods. There are various ways of how to achieve that, but Reciprocal Rank Fusion is the most popular technique. It is based on the rankings of the documents in each methods used, and these rankings are used to calculate the final scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1e0ba70-2b61-4367-8968-38a266b699e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrf_search(query: str, limit: int = 1) -> list[models.ScoredPoint]:\n",
    "    results = client.query_points(\n",
    "        collection_name=\"zoomcamp-sparse-and-dense\",\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"jinaai/jina-embeddings-v2-small-en\",\n",
    "                ),\n",
    "                using=\"jina-small\",\n",
    "                limit=(5 * limit),\n",
    "            ),\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"Qdrant/bm25\",\n",
    "                ),\n",
    "                using=\"bm25\",\n",
    "                limit=(5 * limit),\n",
    "            ),\n",
    "        ],\n",
    "        # Fusion query enables fusion on the prefetched results\n",
    "        query=models.FusionQuery(fusion=models.Fusion.RRF),\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "    return results.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b82f7767-fe5c-485a-a5f7-14d5ad34bf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"text\": \"Even though the upload works using aws cli and boto3 in Jupyter notebook.\\nSolution set the AWS_PROFILE environment variable (the default profile is called default)\",\n",
      "    \"section\": \"Module 4: Deployment\",\n",
      "    \"question\": \"Uploading to s3 fails with An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The AWS Access Key Id you provided does not exist in our records.\\\"\"\n",
      "}\n",
      "When executing an AWS CLI command (e.g., aws s3 ls), you can get the error <botocore.awsrequest.AWSRequest object at 0x7fbaf2666280>.\n",
      "To fix it, simply set the AWS CLI environment variables:\n",
      "export AWS_DEFAULT_REGION=eu-west-1\n",
      "export AWS_ACCESS_KEY_ID=foobar\n",
      "export AWS_SECRET_ACCESS_KEY=foobar\n",
      "Their value is not important; anything would be ok.\n",
      "Added by Giovanni Pecoraro\n"
     ]
    }
   ],
   "source": [
    "results = rrf_search(course_piece[\"question\"])\n",
    "print(json.dumps(course_piece, indent=4))\n",
    "print(results[0].payload[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc1b985-39d8-4516-8481-40f15d3ce1f9",
   "metadata": {},
   "source": [
    "## Reranking\n",
    "Reranking is a broader term related to Hybrid Search. Fusion is one of the ways to rerank the results of multiple methods, but you can also apply a slower method that won't be effective enough to search over all the documents. But there is more to it. Business rules are often important for retrieval, as you prefer to show documents coming from the most recent news, for instance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
